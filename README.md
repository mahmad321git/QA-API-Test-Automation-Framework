# QA-API-Test-Automation-Framework

â—ï¸ ğ—£ğ—¿ğ—¼ğ—¯ğ—¹ğ—²ğ—º - ğ—¦ğ˜ğ—®ğ˜ğ—²ğ—ºğ—²ğ—»ğ˜:
There are several # of backend API's that are built and linked with the on-premise database and have been migrated onto the cloud. These are being built using the micro-services architecture. As an Automation Enginner you have to verify that API'S are successfully migrated.

ğŸ”ª ğ—£ğ—¿ğ—¼ğ—¯ğ—¹ğ—²ğ—º - ğ—¦ğ—¼ğ—¹ğ˜‚ğ˜ğ—¶ğ—¼ğ—»:
So in-order to solve this problem first we have to identify how many services that needs to be tested? and with in each service how many API's that are being built? and with-in each API how many different end points it has?</br>

<p> Lets take an Considerate Assumption:</br>
- # of Services that needs to be tested: 10</br>
- # of API's that Exist with in the service: 10</br>
- # of End points with in an API: 10 </br></p>

ğŸ“ ğ—œğ—ºğ—½ğ—¼ğ—¿ğ˜ğ—®ğ—»ğ˜ ğ—™ğ—¿ğ—®ğ—ºğ—²ğ˜„ğ—¼ğ—¿ğ—¸ & ğ—Ÿğ—¶ğ—¯ğ—¿ğ—®ğ—¿ğ—¶ğ—²ğ˜€ ğ˜‚ğ˜€ğ—²ğ—±:
- RestAssured</br>
- TestNg</br>

ğŸ“œ ğ—™ğ—¼ğ—¿ ğ—¿ğ—²ğ—½ğ—¼ğ—¿ğ˜ğ—¶ğ—»ğ—´ ğ˜„ğ—² ğ—µğ—®ğ˜ƒğ—² ğ˜‚ğ˜€ğ—²ğ—±:
- Extent Report</br>

ğŸ‘‰ ğ—¦ğ—¶ğ—¹ğ—²ğ—»ğ˜ ğ—™ğ—²ğ—®ğ˜ğ˜‚ğ—¿ğ—²ğ˜€ ğ—¼ğ—³ ğ—”ğ˜‚ğ˜ğ—¼ğ—ºğ—®ğ˜ğ—¶ğ—¼ğ—» ğ—™ğ—¿ğ—®ğ—ºğ—²ğ˜„ğ—¼ğ—¿ğ—¸:
- RESTful API Support</br>
- Configurable API endpoints from a separate config file</br>
- Cross-Environment execution feasibility</br>
- Parallel test case execution feasibility</br>
- Retry Mechanism in case of failure (Configurable)</br>
- Test Suite Management (Configurable)</br>
- API vs API comparison (JSON Payloads & Responses)</br>
  - Response Code Validation (Source vs Target)</br>
  - Response Body [Data+Attributes] Validation (Source vs Target)</br>
- A concise html test result report yielded as Extent Report</br>
- Test Results email as an attachment to desired audience via AWS SES (Simple Email Service)</br>

âœ“ ğ—£ğ—¿ğ—²-ğ—¥ğ—²ğ—¾ğ˜‚ğ—¶ğ˜€ğ—¶ğ˜ğ—²ğ˜€:
- Editor: Intellij
- Language: Java

ğŸ² ğ—–ğ—¹ğ—¼ğ—»ğ—¶ğ—»ğ—´ & ğ—¦ğ—²ğ˜ğ˜‚ğ—½ ğ—šğ˜‚ğ—¶ğ—±ğ—²:


â› ğ—˜ğ˜…ğ—²ğ—°ğ˜‚ğ˜ğ—¶ğ—¼ğ—» ğ—™ğ—¶ğ—¹ğ—²ğ˜€:
